{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import scipy\n",
    "from IPython.display import display\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\"\n",
    "    Seed everything.\n",
    "    \"\"\"   \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(model, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for df_name in ['address', 'application', 'client', 'document', 'phone', 'work']:\n",
    "    df = pd.read_csv(f'../data/csv_data/{df_name}.csv')\n",
    "    if df_name == 'client':\n",
    "        df['sex'] = df['sex'].fillna(df['middlename'].str[-1] == 'Ð°').astype(np.bool_)\n",
    "    data[df_name] = df\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['regionname', 'regioncode', 'countrycode', 'street', 'house',\n",
    "              'opendate', 'appdatetime', 'signdate', 'card_number', 'client_snils', 'client_inn',\n",
    "              'lastname', 'firstname', 'middlename', 'birthplacetown', 'birthdate',\n",
    "              'series', 'number', 'issuedate', 'issuercode', 'issuer', \n",
    "              'phone_number',\n",
    "              'title', 'inn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text, y_text = [], []\n",
    "X_numb, y_numb = [], []\n",
    "X_text_test, y_text_test = [], []\n",
    "X_numb_test, y_numb_test = [], []\n",
    "test_data = {}\n",
    "for df_name, df in data.items():\n",
    "    X_train, X_test = model_selection.train_test_split(df, test_size=0.2, shuffle=True)\n",
    "    test_data[df_name] = X_test\n",
    "    for col_name, series in X_train.iteritems():\n",
    "        category = col_name if col_name in categories else 'other'\n",
    "        if 'date' in category:\n",
    "            category = 'date'\n",
    "        elif category in ['client_inn', 'inn']:\n",
    "            category = 'client_inn'\n",
    "        target = pd.Series([category] * len(series), name='target')\n",
    "        if series.dtype == object:\n",
    "            X_text.append(series)\n",
    "            y_text.append(target)\n",
    "        else:\n",
    "            X_numb.append(series)\n",
    "            y_numb.append(target)\n",
    "            \n",
    "    for col_name, series in X_test.iteritems():\n",
    "        category = col_name if col_name in categories else 'other'\n",
    "        if 'date' in category:\n",
    "            category = 'date'\n",
    "        elif category in ['client_inn', 'inn']:\n",
    "            category = 'client_inn'\n",
    "        target = pd.Series([category] * len(series), name='target')\n",
    "        if series.dtype == object:\n",
    "            X_text_test.append(series)\n",
    "            y_text_test.append(target)\n",
    "        else:\n",
    "            X_numb_test.append(series)\n",
    "            y_numb_test.append(target)\n",
    "del series, target, col_name, X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in test_data.items():\n",
    "    df.to_csv(f'../data/test_data/{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = pd.concat(X_text)\n",
    "y_text = pd.concat(y_text)\n",
    "X_numb = pd.concat(X_numb)\n",
    "y_numb = pd.concat(y_numb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_test = pd.concat(X_text_test)\n",
    "y_text_test = pd.concat(y_text_test)\n",
    "X_numb_test = pd.concat(X_numb_test)\n",
    "y_numb_test = pd.concat(y_numb_test)\n",
    "\n",
    "X_text_test.dropna().to_csv('../data/test_data/X_text_test_raw.csv', index=False)\n",
    "X_numb_test.dropna().to_csv('../data/test_data/X_numb_test_raw.csv', index=False)\n",
    "y_text_test.dropna().to_csv('../data/test_data/y_text_test_raw.csv', index=False)\n",
    "y_numb_test.dropna().to_csv('../data/test_data/y_numb_test_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_label_encoder = preprocessing.LabelEncoder()\n",
    "y_text_lbl = text_label_encoder.fit_transform(y_text)\n",
    "numb_label_encoder = preprocessing.LabelEncoder()\n",
    "y_numb_lbl = numb_label_encoder.fit_transform(y_numb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['birthplacetown', 'countrycode', 'date', 'firstname', 'house',\n",
       "       'issuer', 'lastname', 'middlename', 'other', 'regionname',\n",
       "       'series', 'street', 'title'], dtype=object)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(text_label_encoder, '../models/text_label_encoder.pkl')\n",
    "save_to_pickle(numb_label_encoder, '../models/numb_label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENSETIVE DATA CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = model_selection.StratifiedKFold(shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(X):\n",
    "    return X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipe = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='NA')),\n",
    "    ('reshape', preprocessing.FunctionTransformer(func=squeeze)),\n",
    "    ('text_feature_extraction', pipeline.FeatureUnion(n_jobs=-1, transformer_list=[\n",
    "        ('count_vectorizer_char_wb', feature_extraction.text.CountVectorizer(analyzer='char_wb', ngram_range=(1,2))),\n",
    "        ('count_vectorizer_char', feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(1,2))),\n",
    "        ('count_vectorizer_word', feature_extraction.text.CountVectorizer(analyzer='word')),\n",
    "        ('tf_idf_vectorizer_char_wb', feature_extraction.text.TfidfVectorizer(analyzer='char_wb', ngram_range=(1,2))),\n",
    "        ('tf_idf_vectorizer_char', feature_extraction.text.TfidfVectorizer(analyzer='char', ngram_range=(1,2))),\n",
    "        ('tf_idf_vectorizer_word', feature_extraction.text.TfidfVectorizer(analyzer='word')),\n",
    "    ])),\n",
    "    ('model', LGBMClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.6min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "cv_text = model_selection.cross_validate(estimator=text_pipe,\n",
    "                                         X=X_text.values.reshape(-1,1),\n",
    "                                         y=y_text_lbl,\n",
    "                                         scoring=['f1_macro', 'roc_auc_ovr'],\n",
    "                                         cv=skf,\n",
    "                                         n_jobs=-1,\n",
    "                                         verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.419942</td>\n",
       "      <td>4.325528</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.984405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.531802</td>\n",
       "      <td>4.145356</td>\n",
       "      <td>0.809060</td>\n",
       "      <td>0.980976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.740987</td>\n",
       "      <td>1.653193</td>\n",
       "      <td>0.811641</td>\n",
       "      <td>0.982909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.844333</td>\n",
       "      <td>4.135791</td>\n",
       "      <td>0.822104</td>\n",
       "      <td>0.983977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.063936</td>\n",
       "      <td>4.397916</td>\n",
       "      <td>0.824528</td>\n",
       "      <td>0.983755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_f1_macro  test_roc_auc_ovr\n",
       "0  93.419942    4.325528       0.824121          0.984405\n",
       "1  93.531802    4.145356       0.809060          0.980976\n",
       "2  98.740987    1.653193       0.811641          0.982909\n",
       "3  91.844333    4.135791       0.822104          0.983977\n",
       "4  92.063936    4.397916       0.824528          0.983755"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_text_pred = model_selection.cross_val_predict(estimator=text_pipe, \n",
    "                                                 X=X_text.values.reshape(-1,1),\n",
    "                                                 y=y_text_lbl,\n",
    "                                                 cv=skf)\n",
    "\n",
    "cv_text_pred = pd.DataFrame({'PRED': text_label_encoder.inverse_transform(cv_text_pred),\n",
    "                             'TRUE': text_label_encoder.inverse_transform(y_text_lbl)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRED</th>\n",
       "      <th>TRUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regionname</td>\n",
       "      <td>regionname</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>issuer</td>\n",
       "      <td>regionname</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>series</td>\n",
       "      <td>regionname</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regionname</td>\n",
       "      <td>regionname</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regionname</td>\n",
       "      <td>regionname</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRED        TRUE\n",
       "0  regionname  regionname\n",
       "1      issuer  regionname\n",
       "2      series  regionname\n",
       "3  regionname  regionname\n",
       "4  regionname  regionname"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_text_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer',\n",
       "                 SimpleImputer(fill_value='NA', strategy='constant')),\n",
       "                ('reshape',\n",
       "                 FunctionTransformer(func=<function squeeze at 0x7fbf9d3cb560>)),\n",
       "                ('text_feature_extraction',\n",
       "                 FeatureUnion(n_jobs=-1,\n",
       "                              transformer_list=[('count_vectorizer_char_wb',\n",
       "                                                 CountVectorizer(analyzer='char_wb',\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('count_vectorizer_char',\n",
       "                                                 CountVectorizer(analyzer='char',\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('count_vectorizer_word',\n",
       "                                                 CountVectorizer()),\n",
       "                                                ('tf_idf_vectorizer_char_wb',\n",
       "                                                 TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('tf_idf_vectorizer_char',\n",
       "                                                 TfidfVectorizer(analyzer='char',\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('tf_idf_vectorizer_word',\n",
       "                                                 TfidfVectorizer())])),\n",
       "                ('model', LGBMClassifier())])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipe.fit(X_text.values.reshape(-1,1), y_text_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(text_pipe, '../models/text_pipe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUMERIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(X: np.array) -> np.array:\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    return np.hstack([X // 10**i for i in range(12)])\n",
    "\n",
    "statistics_transformer = preprocessing.FunctionTransformer(func=get_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_pipe = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(fill_value=-1, strategy='constant')),\n",
    "    ('statistics', statistics_transformer),\n",
    "    ('model', LGBMClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.2s remaining:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "cv_numb = model_selection.cross_validate(estimator=numb_pipe,\n",
    "                                         X=X_numb.values.reshape(-1,1),\n",
    "                                         y=y_numb_lbl,\n",
    "                                         scoring=['f1_macro', 'roc_auc_ovr'],\n",
    "                                         n_jobs=-1,\n",
    "                                         verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.899663</td>\n",
       "      <td>1.314537</td>\n",
       "      <td>0.753462</td>\n",
       "      <td>0.965469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.897893</td>\n",
       "      <td>1.241724</td>\n",
       "      <td>0.817514</td>\n",
       "      <td>0.972279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.877337</td>\n",
       "      <td>1.334542</td>\n",
       "      <td>0.743969</td>\n",
       "      <td>0.946608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.104791</td>\n",
       "      <td>0.979829</td>\n",
       "      <td>0.847346</td>\n",
       "      <td>0.986803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.110117</td>\n",
       "      <td>1.178703</td>\n",
       "      <td>0.713693</td>\n",
       "      <td>0.937371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_f1_macro  test_roc_auc_ovr\n",
       "0  3.899663    1.314537       0.753462          0.965469\n",
       "1  3.897893    1.241724       0.817514          0.972279\n",
       "2  3.877337    1.334542       0.743969          0.946608\n",
       "3  4.104791    0.979829       0.847346          0.986803\n",
       "4  4.110117    1.178703       0.713693          0.937371"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_numb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_numb_pred = model_selection.cross_val_predict(estimator=numb_pipe, \n",
    "                                                 X=X_numb.values.reshape(-1,1), \n",
    "                                                 y=y_numb_lbl)\n",
    "\n",
    "cv_numb_pred = pd.DataFrame({'PRED': numb_label_encoder.inverse_transform(cv_numb_pred),\n",
    "                             'TRUE': numb_label_encoder.inverse_transform(y_numb_lbl)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRED</th>\n",
       "      <th>TRUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRED   TRUE\n",
       "0  other  other\n",
       "1  other  other\n",
       "2  other  other\n",
       "3  other  other\n",
       "4  other  other"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_numb_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(fill_value=-1, strategy='constant')),\n",
       "                ('statistics',\n",
       "                 FunctionTransformer(func=<function get_stats at 0x7fbf855cd950>)),\n",
       "                ('model', LGBMClassifier())])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_pipe.fit(X=X_numb.values.reshape(-1,1), y=y_numb_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(numb_pipe, '../models/numb_pipe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING SENSETIVE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÐÐ°Ð»Ð¸Ñ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÐÐ°Ð½Ð¶ÐµÐ»Ð»Ð°</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÐÐ±Ð°</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ÐÐ±Ð°Ð²</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ÐÐ±Ð°Ð¼</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  firstname   sex\n",
       "0     ÐÐ°Ð»Ð¸Ñ  True\n",
       "1  ÐÐ°Ð½Ð¶ÐµÐ»Ð»Ð°  True\n",
       "2       ÐÐ±Ð°  True\n",
       "3      ÐÐ±Ð°Ð²  True\n",
       "4      ÐÐ±Ð°Ð¼  True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÐÐ°Ð»ÑÐµÑÐ¾Ð²</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÐÐ°Ð»ÑÐµÑÐ¾Ð²Ð°</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÐÐ°Ð»Ñ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ÐÐ°Ð¼Ð°Ð½</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ÐÐ°Ð¼Ð°Ð½Ð°</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lastname    sex\n",
       "0   ÐÐ°Ð»ÑÐµÑÐ¾Ð²  False\n",
       "1  ÐÐ°Ð»ÑÐµÑÐ¾Ð²Ð°   True\n",
       "2       ÐÐ°Ð»Ñ  False\n",
       "3      ÐÐ°Ð¼Ð°Ð½  False\n",
       "4     ÐÐ°Ð¼Ð°Ð½Ð°   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>middlename</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÐÐ¸ÑÐ°Ð¹Ð»Ð¾Ð²Ð½Ð°</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÐÐ°Ð»ÐµÑÐ¸ÐµÐ²Ð¸Ñ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÐÐºÑÑÐ±ÑÑÑÐ¾Ð²Ð½Ð°</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ÐÐ¸ÑÐ¾Ð´Ð°ÑÐ¾Ð²Ð¸Ñ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ÐÐ°Ð»ÐµÐ½ÑÐ¸Ð½Ð¾Ð²Ð½Ð°</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     middlename    sex\n",
       "0    ÐÐ¸ÑÐ°Ð¹Ð»Ð¾Ð²Ð½Ð°   True\n",
       "1    ÐÐ°Ð»ÐµÑÐ¸ÐµÐ²Ð¸Ñ  False\n",
       "2  ÐÐºÑÑÐ±ÑÑÑÐ¾Ð²Ð½Ð°   True\n",
       "3   ÐÐ¸ÑÐ¾Ð´Ð°ÑÐ¾Ð²Ð¸Ñ  False\n",
       "4  ÐÐ°Ð»ÐµÐ½ÑÐ¸Ð½Ð¾Ð²Ð½Ð°   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NAMES = (pd.read_csv('../data/csv_data/russian_names.csv', sep=';', usecols=['Name', 'Sex'])\n",
    "        .replace({'Sex':{'Ð': 1, 'Ð': 0}})\n",
    "        .rename(columns={'Name': 'firstname', 'Sex': 'sex'})\n",
    "        .astype({'sex': np.bool_}))\n",
    "SURNAMES = pd.read_csv('../data/csv_data/russian_surnames.csv', sep=';', usecols=['Surname', 'Sex'])\n",
    "SURNAMES['Sex'] = SURNAMES['Surname'].str[-1] == 'Ð°'\n",
    "SURNAMES = (SURNAMES.astype({'Sex': np.bool_})\n",
    "                    .rename(columns={'Surname': 'lastname', 'Sex': 'sex'}))\n",
    "MIDDLENAMES = data['client'][['middlename']].drop_duplicates()\n",
    "MIDDLENAMES['sex'] = MIDDLENAMES['middlename'].str[-1] == 'Ð°'\n",
    "\n",
    "\n",
    "display(NAMES.head())\n",
    "display(SURNAMES.head())\n",
    "display(MIDDLENAMES.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(NAMES, '../data/catalogs/names.pkl')\n",
    "save_to_pickle(SURNAMES, '../data/catalogs/surnames.pkl')\n",
    "save_to_pickle(MIDDLENAMES, '../data/catalogs/middlenames.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_names(original_names: pd.DataFrame, fake_names: pd.DataFrame, name_col: str) -> pd.Series:\n",
    "    # Ñ ÑÐµÑÐ¸Ð» Ð¾ÑÐ¸ÐµÐ½ÑÐ¸ÑÐ¾Ð²Ð°ÑÑÑÑ Ð½Ð° Ð¿Ð¾Ð»Ðµ sex Ð² Ð¸ÑÑÐ¾Ð´Ð½ÑÑ Ð´Ð°Ð½Ð½ÑÑ Ð¿ÑÐ¸ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ Ð¸Ð¼ÐµÐ½Ð¸ Ð¾Ð¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð´Ð°\n",
    "    # ÑÐ°Ðº ÐºÐ°Ðº ÑÐ°Ð¼Ð¸ Ð¸Ð¼ÐµÐ½Ð° Ð¾ÑÐµÐ½Ñ Ð³ÑÑÐ·Ð½ÑÐµ, ÑÐ°ÑÑÐ¾ Ð¿Ð¾ ÑÐ¾Ð´Ñ Ð½Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÑÑ Ð¸Ð¼Ñ, Ð¾ÑÑÐµÑÑÐ²Ð¾ Ð¸ ÑÐ°Ð¼Ð¸Ð»Ð¸Ñ\n",
    "    \n",
    "    assert ('sex' in original_names) and ('sex' in fake_names)\n",
    "    assert set(original_names['sex']) >= set(fake_names['sex'])\n",
    "    \n",
    "    for sex in original_names['sex'].unique():\n",
    "        orig_mask = original_names['sex'] == sex\n",
    "        fake_mask = fake_names['sex'] == sex\n",
    "        \n",
    "        sample_fake_names = fake_names.loc[fake_mask, name_col].sample(sum(orig_mask), replace=True).values\n",
    "        mapping = {orig_name: np.random.choice(sample_fake_names) for orig_name in original_names.loc[orig_mask, name_col].unique()}\n",
    "        \n",
    "        original_names.loc[orig_mask, name_col] = original_names.loc[orig_mask, name_col].map(mapping)\n",
    "        \n",
    "    null_mask = original_names[name_col].isnull()\n",
    "    if sum(null_mask) > 0:\n",
    "        original_names[name_col] = original_names[name_col].fillna(fake_names[name_col].sample(sum(null_mask)).values)\n",
    "        \n",
    "    return original_names[name_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITIES = pd.read_csv('../data/csv_data/koord_russia.csv', sep=';', encoding='cp1251', usecols=['ÐÐ¾ÑÐ¾Ð´'])['ÐÐ¾ÑÐ¾Ð´']\n",
    "save_to_pickle(CITIES, '../data/catalogs/cities.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_geodata(original: pd.Series, fake: pd.Series) -> pd.Series:\n",
    "    # Ñ ÑÐµÑÐ¸Ð» Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°ÑÑ Ð³Ð¾ÑÐ¾Ð´Ð° Ð¸ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑÐµÐ³Ð¸Ð¾Ð½Ð¾Ð² \"ÐºÐ°Ðº ÐµÑÑÑ\". Ð¢Ð°Ðº ÐºÐ°Ðº Ð² ÑÐµÐ°Ð»ÑÐ½Ð¾Ð¹ Ð¶Ð¸Ð·Ð½Ð¸ Ð¾Ð±ÑÑÐ½Ð¾ Ð´Ð°Ð½Ð½ÑÐµ Ñ Ð³Ð¾ÑÐ¾Ð´Ð¾Ð¼ Ð¾Ð±ÑÑÐ½Ð¾ Ð¿ÑÐ¸Ð²ÐµÐ´ÐµÐ½Ñ Ðº Ð½Ð¾ÑÐ¼Ð°Ð»ÑÐ½Ð¾Ð¼Ñ Ð²Ð¸Ð´Ñ\n",
    "    # Ð¸ Ð½Ð¾ÑÐ¼Ð°Ð»Ð¸Ð·Ð°ÑÐ¸Ñ Ð¸ Ð¾ÑÐ¸ÑÑÐºÐ° Ð´Ð°Ð½Ð½ÑÑ Ð½Ðµ Ð·Ð°Ð´Ð°ÑÐ° Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½ÑÐµÑÑÐ°\n",
    "    \n",
    "    sample_fake_names = fake.sample(len(original), replace=True).values\n",
    "    mapping = {orig_name: np.random.choice(sample_fake_names) for orig_name in original.unique()}\n",
    "\n",
    "    original = original.map(mapping)\n",
    "    return original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIRTH DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_date(original_dates: pd.Series, date_format='%Y-%m-%d') -> pd.Series:\n",
    "    # ÑÑÑ Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼Ð¾ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ ÐºÐ°ÐºÐ¸Ðµ ÑÐ²Ð¾Ð¹ÑÑÐ²Ð° Ð² ÑÐµÐ»Ð¾Ð¼ Ð´Ð¾Ð»Ð¶Ð½Ñ Ð¾ÑÑÐ°Ð²Ð°ÑÑÑÑ \n",
    "    # Ñ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð½ÑÑ Ð´Ð°Ð½Ð½ÑÑ. Ð¯ Ð¿ÑÐ¸Ð½ÑÐ» ÑÐµÑÐµÐ½Ð¸Ðµ Ð´Ð¾Ð±Ð°Ð²Ð¸ÑÑ ÑÐ»ÑÑÐ°Ð¹Ð½Ð¾ +- 90 Ð´Ð½ÐµÐ¹ Ðº Ð¾ÑÐ¸Ð³Ð¸Ð½Ð°Ð»ÑÐ½Ð¾Ð¹ Ð´Ð°ÑÐµ ÑÐ¾Ð¶Ð´ÐµÐ½Ð¸Ñ\n",
    "    # ÑÑÐ¾Ð±Ñ ÑÐ¾ÑÑÐ°Ð½Ð¸ÑÑ Ð¸ Ð½ÐµÐºÐ¾ÑÐ¾ÑÑÐµ Ð¾Ð±ÑÐ¸Ðµ ÑÐ²Ð¾Ð¹ÑÑÐ²Ð° ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð¸ÐµÑ Ð´Ð°Ñ Ð¸ Ð² ÑÐ¾ Ð¶Ðµ Ð²ÑÐµÐ¼Ñ Ð°Ð½Ð¾Ð½Ð¸Ð¼Ð¸Ð·Ð¸ÑÐ¾Ð²Ð°ÑÑ Ð´Ð°Ð½Ð½ÑÐµ\n",
    "    \n",
    "    if not np.issubdtype(original_dates.dtype , np.datetime64):\n",
    "        original_dates = pd.to_datetime(original_dates, format=date_format)\n",
    "    return original_dates.apply(lambda x: x + pd.Timedelta(days=np.random.randint(1,90)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['address', 'application', 'client', 'document', 'phone', 'work'])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = pd.read_csv('../data/csv_data/koord_russia.csv', sep=';', encoding='cp1251', usecols=['Ð ÐµÐ³Ð¸Ð¾Ð½'])['Ð ÐµÐ³Ð¸Ð¾Ð½'].drop_duplicates()\n",
    "STREETS = data['address']['street'].drop_duplicates().dropna().values\n",
    "HOUSES = pd.Series(list(range(150)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(REGIONS, '../data/catalogs/regions.pkl')\n",
    "save_to_pickle(STREETS, '../data/catalogs/streets.pkl')\n",
    "save_to_pickle(HOUSES, '../data/catalogs/houses.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ð¡ÐÐÐÐ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snils_generator() -> pd.Series:\n",
    "    def _generate_snils_number() -> np.array:\n",
    "        return np.random.randint(0, 9, size=9)\n",
    "    \n",
    "    def _get_control_number(sum_: int) -> str:\n",
    "        if sum_ < 100:\n",
    "            control_number = str(sum_)\n",
    "        elif 100 <= sum_ <= 101:\n",
    "            control_number = '00'\n",
    "        else:\n",
    "            raise ValueError('sum_ should be <= 101')\n",
    "        return control_number\n",
    "\n",
    "    def _check_snils_number(snils_number: np.array) -> bool:\n",
    "        first_triple = int(''.join(map(str, snils_number[:3])))\n",
    "        second_triple = int(''.join(map(str, snils_number[3:6])))\n",
    "        third_triple = int(''.join(map(str, snils_number[6:9])))\n",
    "        if first_triple > 1:\n",
    "            return True\n",
    "        elif second_triple > 1:\n",
    "            return True\n",
    "        elif third_triple > 998:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    snils_number = _generate_snils_number()\n",
    "    while not _check_snils_number(snils_number):\n",
    "        snils_number = _generate_snils_number()\n",
    "    s = sum([i * n for i, n in zip(list(range(1,10))[::-1], snils_number)])\n",
    "    \n",
    "    while s > 101:\n",
    "        s = s % 101\n",
    "    control_number = _get_control_number(s)\n",
    "    return ''.join(map(str, snils_number)) + control_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÐÐÐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inn_ctrl_summ(nums, type):\n",
    "    \"\"\"\n",
    "    ÐÐ¾Ð´ÑÑÐµÑ ÐºÐ¾Ð½ÑÑÐ¾Ð»ÑÐ½Ð¾Ð¹ ÑÑÐ¼Ð¼Ñ\n",
    "    \"\"\"\n",
    "    inn_ctrl_type = {\n",
    "        'n2_12': [7, 2, 4, 10, 3, 5, 9, 4, 6, 8],\n",
    "        'n1_12': [3, 7, 2, 4, 10, 3, 5, 9, 4, 6, 8],\n",
    "        'n1_10': [2, 4, 10, 3, 5, 9, 4, 6, 8],\n",
    "    }\n",
    "    n = 0\n",
    "    l = inn_ctrl_type[type]\n",
    "    for i in range(0, len(l)):\n",
    "        n += nums[i] * l[i]\n",
    "    return n % 11 % 10\n",
    "\n",
    "\n",
    "def inn_gen(l=None):\n",
    "    def rnd(low: int, high: int) -> int:\n",
    "        return np.random.randint(low, high)\n",
    "    \"\"\"\n",
    "    ÐÐµÐ½ÐµÑÐ°ÑÐ¸Ñ ÐÐÐ (10 Ð¸Ð»Ð¸ 12 Ð·Ð½Ð°ÑÐ½ÑÐ¹)\n",
    "    ÐÐ° Ð²ÑÐ¾Ð´Ðµ ÑÐºÐ°Ð·ÑÐ²Ð°ÐµÑÑÑ Ð´Ð»Ð¸Ð½Ð° Ð½Ð¾Ð¼ÐµÑÐ° - 10 Ð¸Ð»Ð¸ 12.\n",
    "    ÐÑÐ»Ð¸ Ð½Ð¸ÑÐµÐ³Ð¾ Ð½Ðµ ÑÐºÐ°Ð·Ð°Ð½Ð¾, Ð±ÑÐ´ÐµÑ Ð²ÑÐ±ÑÐ°Ð½Ð° ÑÐ»ÑÑÐ°Ð¹Ð½Ð°Ñ Ð´Ð»Ð¸Ð½Ð°.\n",
    "    \"\"\"\n",
    "    if not l:\n",
    "        l = list((10, 12))[rnd(0, 1)]\n",
    "    if l not in (10, 12):\n",
    "        return None\n",
    "    nums = [\n",
    "        rnd(1, 9) if x == 0\n",
    "        else rnd(0, 9)\n",
    "        for x in range(0, 9 if l == 10 else 10)\n",
    "    ]\n",
    "    if l == 12:\n",
    "        n2 = inn_ctrl_summ(nums, 'n2_12')\n",
    "        nums.append(n2)\n",
    "        n1 = inn_ctrl_summ(nums, 'n1_12')\n",
    "        nums.append(n1)\n",
    "    elif l == 10:\n",
    "        n1 = inn_ctrl_summ(nums, 'n1_10')\n",
    "        nums.append(n1)\n",
    "    return ''.join([str(x) for x in nums])\n",
    "\n",
    "\n",
    "def inn_check(inn):\n",
    "    \"\"\"\n",
    "    ÐÑÐ¾Ð²ÐµÑÐºÐ° ÐÐÐ Ð½Ð° ÐºÐ¾ÑÑÐµÐºÑÐ½Ð¾ÑÑÑ\n",
    "    Ð ÑÐ¾Ð¾ÑÐ²ÐµÑÑÑÐ²Ð¸Ð¸ Ñ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼Ð¾Ð¼, Ð¾Ð¿Ð¸ÑÐ°Ð½Ð½ÑÐ¼ Ð¿Ð¾ ÑÑÑÐ»ÐºÐµ:\n",
    "        https://ru.wikipedia.org/wiki/ÐÐ¾Ð½ÑÑÐ¾Ð»ÑÐ½Ð¾Ðµ_ÑÐ¸ÑÐ»Ð¾\n",
    "    \"\"\"\n",
    "    sinn = str(inn)\n",
    "    nums = [int(x) for x in sinn]\n",
    "    if len(sinn) == 10:\n",
    "        n1 = inn_ctrl_summ(nums, 'n1_10')\n",
    "        return n1 == nums[-1]\n",
    "    elif len(sinn) == 12:\n",
    "        n2 = inn_ctrl_summ(nums, 'n2_12')\n",
    "        n1 = inn_ctrl_summ(nums, 'n1_12')\n",
    "        return n2 == nums[-2] and n1 == nums[-1]\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>documenttype</th>\n",
       "      <th>series</th>\n",
       "      <th>number</th>\n",
       "      <th>issuedate</th>\n",
       "      <th>issuercode</th>\n",
       "      <th>issuer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>2300155167</td>\n",
       "      <td>621180</td>\n",
       "      <td>2000897397</td>\n",
       "      <td>434367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8921</td>\n",
       "      <td>914923.0</td>\n",
       "      <td>2005-06-21</td>\n",
       "      <td>193051.0</td>\n",
       "      <td>ÐÐÐ Ð ÐÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ ÐÐÐ£Ð Ð¡ÐÐÐ ÐÐÐ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2300155421</td>\n",
       "      <td>621519</td>\n",
       "      <td>2000898198</td>\n",
       "      <td>434735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3830</td>\n",
       "      <td>77174.0</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>386804.0</td>\n",
       "      <td>ÐÐ£ ÐÐÐ Ð ÐÐ¡Ð¡ÐÐ ÐÐ ÐÐÐÐÐÐÐ ÐÐÐ¡ÐÐÐ ÐÐÐ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2300155167</td>\n",
       "      <td>621393</td>\n",
       "      <td>2000897397</td>\n",
       "      <td>434603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8921</td>\n",
       "      <td>914923.0</td>\n",
       "      <td>2005-06-21</td>\n",
       "      <td>193051.0</td>\n",
       "      <td>ÐÐÐ Ð ÐÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ ÐÐÐ£Ð Ð¡ÐÐÐ ÐÐÐ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2300154808</td>\n",
       "      <td>620754</td>\n",
       "      <td>2000895597</td>\n",
       "      <td>433870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1237</td>\n",
       "      <td>874531.0</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>386802.0</td>\n",
       "      <td>ÐÐÐ ÐÐ Ð£ÐÐÐ£Ð Ð¢Ð¡ÐÐÐ Ð ÐÐ¡Ð.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2300154744</td>\n",
       "      <td>620696</td>\n",
       "      <td>2000895122</td>\n",
       "      <td>433802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9683</td>\n",
       "      <td>641994.0</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>931210.0</td>\n",
       "      <td>ÐÐÐÐÐÐ¡ÐÐÐ Ð ÐÐÐ ÐÐ ÐÐ¡ÐÐÐÐÐ Ð¡ÐÐÐÐ ÐÐ ÐÐ¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>2300152876</td>\n",
       "      <td>619707</td>\n",
       "      <td>2000886000</td>\n",
       "      <td>432722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3830</td>\n",
       "      <td>642075.0</td>\n",
       "      <td>2012-01-22</td>\n",
       "      <td>386808.0</td>\n",
       "      <td>ÐÐ¢ÐÐÐÐÐÐÐÐ Ð£Ð¤ÐÐ¡ Ð ÐÐ¡Ð¡ÐÐ ÐÐ ÐÐÐÐÐÐÐÐÐ¬Ð¡ÐÐÐÐ£ ÐÐ ÐÐ® ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>2300155111</td>\n",
       "      <td>621088</td>\n",
       "      <td>2000897197</td>\n",
       "      <td>434253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6191</td>\n",
       "      <td>626874.0</td>\n",
       "      <td>2016-09-23</td>\n",
       "      <td>435696.0</td>\n",
       "      <td>2 ÐÐ ÐÐÐÐÐÐ¡ÐÐÐÐ Ð£ÐÐ ÐÐÐÐÐ ÐÐÐ¡ÐÐÐ ÐÐÐ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>2300155551</td>\n",
       "      <td>621657</td>\n",
       "      <td>2000898898</td>\n",
       "      <td>434883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1235</td>\n",
       "      <td>874530.0</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>386802.0</td>\n",
       "      <td>ÐÐÐ ÐÐ Ð£ÐÐÐ£Ð Ð¢Ð¡ÐÐÐ Ð ÐÐ¡Ð.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>2300155416</td>\n",
       "      <td>621473</td>\n",
       "      <td>2000898030</td>\n",
       "      <td>434686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6041</td>\n",
       "      <td>471986.0</td>\n",
       "      <td>2010-06-18</td>\n",
       "      <td>386908.0</td>\n",
       "      <td>ÐÐÐ Ð¡ÐÐ ÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ Ð¡ÐÐÐÐ Ð¡ÐÐÐ ÐÐÐ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>2300155607</td>\n",
       "      <td>621723</td>\n",
       "      <td>2000899197</td>\n",
       "      <td>434950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6244</td>\n",
       "      <td>881951.0</td>\n",
       "      <td>2010-06-18</td>\n",
       "      <td>386908.0</td>\n",
       "      <td>ÐÐÐ Ð¡ÐÐ ÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ Ð¡ÐÐÐÐ Ð¡ÐÐÐ ÐÐÐ.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          app_id  run_id   client_id  document_id  documenttype series  \\\n",
       "1266  2300155167  621180  2000897397       434367           1.0   8921   \n",
       "2996  2300155421  621519  2000898198       434735           1.0   3830   \n",
       "2827  2300155167  621393  2000897397       434603           1.0   8921   \n",
       "2556  2300154808  620754  2000895597       433870           1.0   1237   \n",
       "933   2300154744  620696  2000895122       433802           1.0   9683   \n",
       "...          ...     ...         ...          ...           ...    ...   \n",
       "2076  2300152876  619707  2000886000       432722           1.0   3830   \n",
       "2759  2300155111  621088  2000897197       434253           1.0   6191   \n",
       "3064  2300155551  621657  2000898898       434883           1.0   1235   \n",
       "1428  2300155416  621473  2000898030       434686           1.0   6041   \n",
       "3092  2300155607  621723  2000899197       434950           1.0   6244   \n",
       "\n",
       "        number   issuedate  issuercode  \\\n",
       "1266  914923.0  2005-06-21    193051.0   \n",
       "2996   77174.0  2015-05-01    386804.0   \n",
       "2827  914923.0  2005-06-21    193051.0   \n",
       "2556  874531.0  2019-06-07    386802.0   \n",
       "933   641994.0  2019-10-10    931210.0   \n",
       "...        ...         ...         ...   \n",
       "2076  642075.0  2012-01-22    386808.0   \n",
       "2759  626874.0  2016-09-23    435696.0   \n",
       "3064  874530.0  2019-06-07    386802.0   \n",
       "1428  471986.0  2010-06-18    386908.0   \n",
       "3092  881951.0  2010-06-18    386908.0   \n",
       "\n",
       "                                                 issuer  \n",
       "1266               ÐÐÐ Ð ÐÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ ÐÐÐ£Ð Ð¡ÐÐÐ ÐÐÐ.  \n",
       "2996                ÐÐ£ ÐÐÐ Ð ÐÐ¡Ð¡ÐÐ ÐÐ ÐÐÐÐÐÐÐ ÐÐÐ¡ÐÐÐ ÐÐÐ.  \n",
       "2827               ÐÐÐ Ð ÐÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ ÐÐÐ£Ð Ð¡ÐÐÐ ÐÐÐ.  \n",
       "2556                            ÐÐÐ ÐÐ Ð£ÐÐÐ£Ð Ð¢Ð¡ÐÐÐ Ð ÐÐ¡Ð.  \n",
       "933                  ÐÐÐÐÐÐ¡ÐÐÐ Ð ÐÐÐ ÐÐ ÐÐ¡ÐÐÐÐÐ Ð¡ÐÐÐÐ ÐÐ ÐÐ¯  \n",
       "...                                                 ...  \n",
       "2076  ÐÐ¢ÐÐÐÐÐÐÐÐ Ð£Ð¤ÐÐ¡ Ð ÐÐ¡Ð¡ÐÐ ÐÐ ÐÐÐÐÐÐÐÐÐ¬Ð¡ÐÐÐÐ£ ÐÐ ÐÐ® ...  \n",
       "2759               2 ÐÐ ÐÐÐÐÐÐ¡ÐÐÐÐ Ð£ÐÐ ÐÐÐÐÐ ÐÐÐ¡ÐÐÐ ÐÐÐ.  \n",
       "3064                            ÐÐÐ ÐÐ Ð£ÐÐÐ£Ð Ð¢Ð¡ÐÐÐ Ð ÐÐ¡Ð.  \n",
       "1428             ÐÐÐ Ð¡ÐÐ ÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ Ð¡ÐÐÐÐ Ð¡ÐÐÐ ÐÐÐ.  \n",
       "3092             ÐÐÐ Ð¡ÐÐ ÐÐÐÐÐ¡ÐÐÐÐ Ð ÐÐÐÐÐ Ð¡ÐÐÐÐ Ð¡ÐÐÐ ÐÐÐ.  \n",
       "\n",
       "[622 rows x 10 columns]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['document']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
